"0","# Implementação do algoritmo do gradiente descendente para obtenção do mesmo resultado da função lm do R"
"0","theta0 = 0"
"0","theta1 = 0"
"0","theta  = c(theta0,theta1)"
"0","# Criando funções"
"0","Cost_computation <- function(x, y, theta){"
"0","  "
"0","  # Verificação do número de exemplos de treinamento "
"0","  m = length(y)"
"0","  "
"0","  # Inicialização do Custo"
"0","  J = 0"
"0","  "
"0","  # Cômputo do custo a partir das informações fornecidas:"
"0","  # i)   matriz de design"
"0","  # ii)  rótulos ou respostas"
"0","  # iii) parâmetros inicializados"
"0","  "
"0","  # Parâmetros - de acordo com o modelo de regressão linear"
"0","  Theta0 = theta[1]"
"0","  Theta1 = theta[2]"
"0","  "
"0","  # Função hipótese candidata de acordo com o modelo linear"
"0","  h = Theta0 + Theta1*x    "
"0","  "
"0","  # Cômputo do custo (repare na versão vetorizada com Matlab)"
"0","  Cost = sum((h - y)^2)"
"0","  "
"0","  # Ponderação do custo pela quantidade de exemplos de treinamento"
"0","  J = (1/(2*m))*Cost"
"0","}"
"0",""
"0","# Cálculo da função custo para esses valores do vetor de parâmetros theta"
"0","Custo = Cost_computation(x,y,theta)"
"0","Custo"
"1","[1]"
"1"," 32.07273"
"1","
"
