---
title: "Exercício Computacional III"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

Considere o mesmo problema de regressão abordado no Exercício 2, ou seja, os dados da biblioteca MASS,
relacionados com o conjunto de dados da cidade de Boston. O objetivo com este exercício consiste em utilizar
mais informações disponíveis no conjunto de dados, isto é, mais features. Isto permite que a regressão linear
múltipla possa ser explorada neste problema.
De forma específica, utilize as features x1 = crim, x2 = rm e x3 = lstat para compor o modelo de regressão linear
múltipla. Isso significa que vão existir quatro parâmetros no modelo de ML (n+1 = 4) para a realização da
regressão linear, de acordo com
hθ (x) = θ0 +θ1x1 +θ2x2 +θ3x3
Abaixo, seguem os itens que devemos solucionar neste desenvolvimento, visando alcançar o objetivo deste
exercício:

– 1) Faça a exploração estatística das variáveis explanatórias crim, rm e lstat.

```{r}
library(MASS)
data <- Boston

summary(data[, names(data) %in% c("crim", "lstat", "rm")])
```

2) Aplique a normalização (feature scaling).

xj = (xj - µj) / σj

```{r}
normalize <- function(x) {
  return ((x - mean(x)) / sd(x))
}

dfNorm = lapply(data[, names(data) %in% c("crim", "lstat", "rm")], normalize) %>% transform(medv = data$medv)
summary(dfNorm)

```

3) Construa e treine o modelo preditivo de ML baseado em regressão linear múltipla
```{r}
modelo_ML <- lm(medv ~ crim + rm + lstat, data = dfNorm)
summary(modelo_ML)

```

4) Realize as predições do modelo sobre os dado de treinamento e calcule a média de seus resíduos.

```{r}
previsao_treinamento <- predict(modelo_ML) %>% as.data.frame()
previsao_treinamento

# Obtenha a média dos resíduos
media_residuos = mean(modelo_ML$residuals)
media_residuos
```

– 5) Qual seria o preço mediano de uma casa na região suburbana de Boston, considerando as seguintes
informações sobre a vizinhança: taxa de criminalidade per capita de crim = 0.15, número médio de
cômodos nas casas rm = 5 e porcentagem da população de baixa renda lstat = 20%?

```{r}
# Novo valor de população (10 mil habitantes) - nós não sabemos a previsibilidade para esse valor de entrada
df2 <-  lapply(data[, names(data) %in% c("crim", "lstat", "rm")] %>% rbind(data.frame(crim = c(0.15), rm = c(5), lstat = c(20))), normalize)
dado_predicao <- data.frame(crim = tail(df2$crim, 1), rm = tail(df2$rm, 1), lstat = tail(df2$lstat, 1))

predicao_teste <- predict(modelo_ML, dado_predicao)
predicao_teste <- data.frame(dado_predicao, predicao_teste*1000)
names(predicao_teste) <- c('Índice de crimes', 'Número de quartos', 'Porcetagem Baixa Renda', 'Predições (dólares)')
predicao_teste$`Predições (dólares)`

```

6 - Implemente o algoritmo do gradiente descendente.
```{r}
X_df_norm = data.frame(crim = data$crim, rm = data$rm, lstat = data$lstat) %>% lapply(normalize) %>% as.data.frame() %>% as.matrix()

y = data$medv
num_iters     = 5000;
learning_rate = 0.01;
gradient <- function(x, y, theta){
  m <- nrow(x)
  grad <-  1/m* t(x) %*% (x %*% theta - y) 
  return(grad)
}

Algoritmo_GD <- function(X, y, learning_rate, num_iters){
  m <- nrow(X)
  theta <- c(0,0,0)
  
  alpha = learning_rate
  
  for (i in 1:num_iters){
    theta <- theta - alpha*gradient(X, y, theta)
  }
  
  return (theta)
}

theta_GD <- Algoritmo_GD(X_df_norm, y, learning_rate, num_iters)
theta_GD
```

7) Solucione o problema de regressão linear com as equações normais e faça um comparativo.

```{r}
summary(modelo_ML)
```


```{r}
# Matriz de Design
X = data.frame(crim = data$crim, rm = data$rm, lstat = data$lstat) %>% lapply(normalize) %>%  as.data.frame() %>% as.matrix()

theta_solution_norm_equations = solve(t(X) %*% X) %*% (t(X) %*% y) 
theta_solution_norm_equations
```